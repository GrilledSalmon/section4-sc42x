{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_9hARVUo9L"
      },
      "source": [
        "# SC42x \n",
        "## 자연어처리 (Natural Language Processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNUXHiLbBdp"
      },
      "source": [
        "# Part 1 : 개념 요약\n",
        "\n",
        "> 다음의 키워드에 대해서 **한 줄**로 간단하게 요약해주세요. (세션 노트를 참고하여도 좋습니다.)<br/>\n",
        "> **Tip : 아래 문제를 먼저 수행한 후 모델 학습 등 시간이 오래 걸리는 셀이 실행되는 동안 아래 내용을 작성하면 시간을 절약할 수 있습니다.**\n",
        "\n",
        "**N421**\n",
        "- Stopwords(불용어) : 분석 대상 말뭉치의 단어들 중 너무 자주 등장해 분석의 의미가 없다고 판단한 단어들의 집합\n",
        "- Stemming과 Lemmatization : 말뭉치를 tokenizing할 때 stemming은 단어의 형태를 변형하지 않고 단어의 중심의미를 갖고 있는 앞부분(어간)만 잘라서 가져오는 것이고, lemmatization은 단어의 형태를 기본형으로 변환하여 가져오는 것이다.\n",
        "- Bag-of-Words : 문장에 등장하는 단어의 횟수만을 고려해 문장을 벡터화하는 방식.\n",
        "- TF-IDF : 문장을 벡터화할 때 잘 등장하지 않는 단어에 가중치를 두어 벡터화하는 방식.\n",
        "\n",
        "**N422**\n",
        "- Word2Vec : 주변에 있는 단어를 단서로 하여 단어를 벡터화하는 방법\n",
        "- fastText : 단어를 벡터화할 때 단어의 구성요소까지 3-6글자 단위로 쪼개 벡터화하는 방법으로 Word2Vec의 OOV 문제를 어느정도 해소할 수 있다.\n",
        "\n",
        "**N423**\n",
        "- RNN : sequential한 데이터를 입력할 때, 지금까지 입력된 데이터를 고려하여 출력값을 리턴하는 신경망 모델.\n",
        "- LSTM, GRU : RNN의 기울기 폭발, 소실 문제를 해소하기 위해 Gate를 추가한 RNN 기반 신경망 모델.\n",
        "- Attention : 각 time-step 마다의 hidden vector를 decoding 시에 활용해 장기 의존성 문제를 해소한 방법."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07_yjCgbBdp"
      },
      "source": [
        "# Part 2 : Fake/Real News Dataset\n",
        "\n",
        "한 주간 자연어처리 기법을 배우면서 여러분은 다양한 기술들을 접했습니다.<br/>\n",
        "어떻게 텍스트 데이터를 다뤄야 하는지, 텍스트를 벡터화 하는 법, 문서에서 토픽을 모델하는 법 등 다양한 NLP 기법을 배웠는데요.<br/>\n",
        "이번 스프린트 챌린지에선 [Fake/Real News Dataset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)을 사용하여 배운 것들을 복습해보는 시간을 갖겠습니다.\n",
        "\n",
        "**주의 : 모델의 성능을 최대한 끌어올리는 것이 아닌 모델 구동에 초점을 맞춰주세요.<br/>\n",
        "모든 문제를 완료한 후에도 \"시간이 남았다면\" 정확도를 올리는 것에 도전하시는 것을 추천드립니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "BCX5K0nP0ZKQ"
      },
      "outputs": [],
      "source": [
        "# 코드 실행 전 seed를 지정하겠습니다.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C08-JiyNbdQy"
      },
      "source": [
        "## 2.0 데이터셋을 불러옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyndWa5hxEmk"
      },
      "source": [
        "- 위 캐글 링크에서 데이터셋을 받아 업로드 합니다.<br/>\n",
        "(직접 업로드하게 되면 시간이 꽤 걸리므로 **drive_mount** 나 **kaggle 연동**하시는 것을 추천드립니다.)\n",
        "\n",
        "- 'label' 열을 만들어 Fake = 1, True = 0 로 레이블링해줍니다.\n",
        "- 두 파일을 합쳐 하나의 데이터프레임에 저장해 준 후 데이터를 섞어줍니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pFzd2G9FtdES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da78bb79-0e84-44bd-fa37-eb7e44516221"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake = pd.read_csv('/content/drive/MyDrive/Fake.csv')\n",
        "df_true = pd.read_csv('/content/drive/MyDrive/True.csv')\n",
        "df_fake['label'] = 0\n",
        "df_true['label'] = 1\n",
        "\n",
        "df_fake.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iWn5IKc5uyEw",
        "outputId": "4a5acc4e-3055-44dd-eeb2-1c5eb29d7c58"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f36f2a95-0af0-4fd6-aa5b-43a03f787c0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f36f2a95-0af0-4fd6-aa5b-43a03f787c0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f36f2a95-0af0-4fd6-aa5b-43a03f787c0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f36f2a95-0af0-4fd6-aa5b-43a03f787c0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...  ...     0\n",
              "1   Drunk Bragging Trump Staffer Started Russian ...  ...     0\n",
              "2   Sheriff David Clarke Becomes An Internet Joke...  ...     0\n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...  ...     0\n",
              "4   Pope Francis Just Called Out Donald Trump Dur...  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_fake, df_true])\n",
        "\n",
        "# 행 섞기\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4RvLKqIxvXYe",
        "outputId": "3eb5b675-8c81-46a7-f550-c7e3bd602312"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9ea920ff-7af8-4e4f-99ad-a3cd0b9928f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
              "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
              "      <td>US_News</td>\n",
              "      <td>February 13, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>April 5, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
              "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 27, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
              "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
              "      <td>News</td>\n",
              "      <td>May 22, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
              "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>June 24, 2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ea920ff-7af8-4e4f-99ad-a3cd0b9928f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ea920ff-7af8-4e4f-99ad-a3cd0b9928f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ea920ff-7af8-4e4f-99ad-a3cd0b9928f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0  Ben Stein Calls Out 9th Circuit Court: Committ...  ...     0\n",
              "1  Trump drops Steve Bannon from National Securit...  ...     1\n",
              "2  Puerto Rico expects U.S. to lift Jones Act shi...  ...     1\n",
              "3   OOPS: Trump Just Accidentally Confirmed He Le...  ...     0\n",
              "4  Donald Trump heads for Scotland to reopen a go...  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbxEHBanUo9d"
      },
      "source": [
        "## 2.1 TF-IDF 를 활용하여 특정 뉴스와 유사한 뉴스 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4R5mLMS5c2I"
      },
      "source": [
        "시간상 특별한 **전처리 없이** 아래 태스크를 수행하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2B-6Wkk5YGD"
      },
      "source": [
        "### 2.1.1 TFidfVectorizer를 사용하여 문서-단어 행렬(Document-Term Matrix) 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "0Kw9OQwmUo9e"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sa1P1BrmyoQt",
        "outputId": "beedd190-e79d-4f6e-9fd9-0ffce4a94c80"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d0197997-932f-4541-a0fc-5345870a83cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
              "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
              "      <td>US_News</td>\n",
              "      <td>February 13, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>April 5, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
              "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 27, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
              "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
              "      <td>News</td>\n",
              "      <td>May 22, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
              "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>June 24, 2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0197997-932f-4541-a0fc-5345870a83cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0197997-932f-4541-a0fc-5345870a83cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0197997-932f-4541-a0fc-5345870a83cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  ... label\n",
              "0  Ben Stein Calls Out 9th Circuit Court: Committ...  ...     0\n",
              "1  Trump drops Steve Bannon from National Securit...  ...     1\n",
              "2  Puerto Rico expects U.S. to lift Jones Act shi...  ...     1\n",
              "3   OOPS: Trump Just Accidentally Confirmed He Le...  ...     0\n",
              "4  Donald Trump heads for Scotland to reopen a go...  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', max_features=100)\n",
        "\n",
        "dtm_tfidf = tfidf.fit_transform(df.text)\n",
        "\n",
        "dtm_tfidf = pd.DataFrame(dtm_tfidf.todense(), columns=tfidf.get_feature_names_out())\n",
        "dtm_tfidf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EZlZ55M9xhrP",
        "outputId": "98c9752f-a2b4-4411-e584-5e0ad121eed3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b141aa8-d12c-4fc0-9c50-d18f39e91b4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>2016</th>\n",
              "      <th>according</th>\n",
              "      <th>administration</th>\n",
              "      <th>america</th>\n",
              "      <th>american</th>\n",
              "      <th>americans</th>\n",
              "      <th>asked</th>\n",
              "      <th>called</th>\n",
              "      <th>campaign</th>\n",
              "      <th>china</th>\n",
              "      <th>city</th>\n",
              "      <th>clinton</th>\n",
              "      <th>committee</th>\n",
              "      <th>congress</th>\n",
              "      <th>country</th>\n",
              "      <th>court</th>\n",
              "      <th>day</th>\n",
              "      <th>democratic</th>\n",
              "      <th>democrats</th>\n",
              "      <th>department</th>\n",
              "      <th>did</th>\n",
              "      <th>don</th>\n",
              "      <th>donald</th>\n",
              "      <th>election</th>\n",
              "      <th>federal</th>\n",
              "      <th>foreign</th>\n",
              "      <th>friday</th>\n",
              "      <th>going</th>\n",
              "      <th>government</th>\n",
              "      <th>group</th>\n",
              "      <th>hillary</th>\n",
              "      <th>house</th>\n",
              "      <th>image</th>\n",
              "      <th>including</th>\n",
              "      <th>just</th>\n",
              "      <th>know</th>\n",
              "      <th>law</th>\n",
              "      <th>like</th>\n",
              "      <th>make</th>\n",
              "      <th>...</th>\n",
              "      <th>public</th>\n",
              "      <th>republican</th>\n",
              "      <th>republicans</th>\n",
              "      <th>reuters</th>\n",
              "      <th>right</th>\n",
              "      <th>russia</th>\n",
              "      <th>russian</th>\n",
              "      <th>said</th>\n",
              "      <th>say</th>\n",
              "      <th>saying</th>\n",
              "      <th>says</th>\n",
              "      <th>secretary</th>\n",
              "      <th>security</th>\n",
              "      <th>senate</th>\n",
              "      <th>state</th>\n",
              "      <th>statement</th>\n",
              "      <th>states</th>\n",
              "      <th>support</th>\n",
              "      <th>tax</th>\n",
              "      <th>think</th>\n",
              "      <th>thursday</th>\n",
              "      <th>time</th>\n",
              "      <th>told</th>\n",
              "      <th>trump</th>\n",
              "      <th>tuesday</th>\n",
              "      <th>twitter</th>\n",
              "      <th>united</th>\n",
              "      <th>vote</th>\n",
              "      <th>want</th>\n",
              "      <th>war</th>\n",
              "      <th>washington</th>\n",
              "      <th>way</th>\n",
              "      <th>wednesday</th>\n",
              "      <th>week</th>\n",
              "      <th>white</th>\n",
              "      <th>women</th>\n",
              "      <th>work</th>\n",
              "      <th>world</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.515299</td>\n",
              "      <td>0.221246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.232898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.175822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420828</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.188896</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.234041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.183190</td>\n",
              "      <td>0.044892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041490</td>\n",
              "      <td>0.041127</td>\n",
              "      <td>0.063003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106183</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031154</td>\n",
              "      <td>0.041156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143978</td>\n",
              "      <td>0.047378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046065</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.261336</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034636</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048403</td>\n",
              "      <td>0.028469</td>\n",
              "      <td>0.042133</td>\n",
              "      <td>0.106736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.281215</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049311</td>\n",
              "      <td>0.447956</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035270</td>\n",
              "      <td>0.044608</td>\n",
              "      <td>0.036522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034431</td>\n",
              "      <td>0.365807</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.075784</td>\n",
              "      <td>0.042245</td>\n",
              "      <td>0.046241</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.240405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045513</td>\n",
              "      <td>0.035526</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347947</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.160179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.19131</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.168594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.190746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.185487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161175</td>\n",
              "      <td>0.141545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.169726</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108148</td>\n",
              "      <td>0.320107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.493046</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.165179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187321</td>\n",
              "      <td>0.170168</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106893</td>\n",
              "      <td>0.3466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.175657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.152444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.141880</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141395</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.113368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.154509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.126035</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.194201</td>\n",
              "      <td>0.412155</td>\n",
              "      <td>0.314866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.158228</td>\n",
              "      <td>0.170005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.511975</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178402</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074386</td>\n",
              "      <td>0.294941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082788</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.069904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077884</td>\n",
              "      <td>0.055856</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258134</td>\n",
              "      <td>0.084943</td>\n",
              "      <td>0.076069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082466</td>\n",
              "      <td>0.066935</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.216238</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163236</td>\n",
              "      <td>0.417837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051042</td>\n",
              "      <td>0.075540</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116350</td>\n",
              "      <td>0.072082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088409</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065480</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.079628</td>\n",
              "      <td>0.084126</td>\n",
              "      <td>0.127939</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.302698</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068501</td>\n",
              "      <td>0.174825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074934</td>\n",
              "      <td>0.071836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b141aa8-d12c-4fc0-9c50-d18f39e91b4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b141aa8-d12c-4fc0-9c50-d18f39e91b4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b141aa8-d12c-4fc0-9c50-d18f39e91b4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   000  2016  according  administration  ...      work     world      year  years\n",
              "0  0.0   0.0   0.000000        0.000000  ...  0.234041  0.000000  0.000000    0.0\n",
              "1  0.0   0.0   0.000000        0.183190  ...  0.000000  0.045513  0.035526    0.0\n",
              "2  0.0   0.0   0.000000        0.347947  ...  0.000000  0.000000  0.000000    0.0\n",
              "3  0.0   0.0   0.152444        0.000000  ...  0.000000  0.000000  0.000000    0.0\n",
              "4  0.0   0.0   0.000000        0.000000  ...  0.000000  0.000000  0.000000    0.0\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeTMNUMM5WgQ"
      },
      "source": [
        "### 2.1.2 KNN 알고리즘을 사용하여 유사한 문서 검색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXqM8aOYr_Y5"
      },
      "source": [
        "- **42번 인덱스의 문서**와 가장 유사한 **5개 문서(42번 포함)의 인덱스**와 **해당 인덱스의 레이블**을 나타내주세요.\n",
        "- NN 모델의 파라미터 중 `algorithm = 'kd_tree'` 로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "8jjaQO8O6UKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af87f7f7-3abc-40b1-9458-a34dc540dc4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nearest_ind = nn.kneighbors([dtm_tfidf.iloc[42]])[1][0]\n",
        "\n",
        "# 가장 유사한 문서 5개의 인덱스와 label\n",
        "df.iloc[nearest_ind]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "y8Jerph-1Ztu",
        "outputId": "aa69c2db-71a7-4023-900f-1967dae87a49"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a56dc3e-d647-4037-b5af-f3de54020c81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33954</th>\n",
              "      <td>WATCH: AMAZING THING HAPPENED When H.S. Valedi...</td>\n",
              "      <td>A 70-year tradition at East Liverpool High Sch...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Jun 27, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>WATCH: AMAZING THING HAPPENED When H.S. Valedi...</td>\n",
              "      <td>A 70-year tradition at East Liverpool High Sch...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>Jun 27, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36664</th>\n",
              "      <td>Heroic Mom Battling Cancer Caught On Camera R...</td>\n",
              "      <td>Cancer can take a lot out of a person, especia...</td>\n",
              "      <td>News</td>\n",
              "      <td>July 30, 2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31854</th>\n",
              "      <td>Queen Elizabeth praises British spirit in Chri...</td>\n",
              "      <td>SANDRINGHAM, England (Reuters) - Britain s Que...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5235</th>\n",
              "      <td>SWEDISH CITIZENS Get DISTURBING News About Lik...</td>\n",
              "      <td>When will government officials who allowed thi...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>Apr 13, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a56dc3e-d647-4037-b5af-f3de54020c81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a56dc3e-d647-4037-b5af-f3de54020c81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a56dc3e-d647-4037-b5af-f3de54020c81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   title  ... label\n",
              "33954  WATCH: AMAZING THING HAPPENED When H.S. Valedi...  ...     0\n",
              "42     WATCH: AMAZING THING HAPPENED When H.S. Valedi...  ...     0\n",
              "36664   Heroic Mom Battling Cancer Caught On Camera R...  ...     0\n",
              "31854  Queen Elizabeth praises British spirit in Chri...  ...     1\n",
              "5235   SWEDISH CITIZENS Get DISTURBING News About Lik...  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQSPbQE7P8b"
      },
      "source": [
        "## 2.2 Keras Embedding을 사용하여 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEl8iU6j8I4M"
      },
      "source": [
        "### 2.2.0 데이터셋 split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq-TglFar_Y6"
      },
      "source": [
        "- Train, Test 데이터셋으로 분리(Split)하여 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "55XSZyY_Sj54"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "X = df.text\n",
        "y = df.label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ3NtInZ3eDM",
        "outputId": "e08a851d-e13c-4dd1-b290-ddc35d4b4bf8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35918,), (8980,))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1xXxSMn7fyt"
      },
      "source": [
        "### 2.2.1 단어 벡터의 평균을 이용하여 분류해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ZsjAVg7ndG"
      },
      "source": [
        "N422에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길고 시간이 오래 걸리므로 시간상 epoch 수를 **10 이하**로 하는 것을 추천드립니다.<br/>\n",
        "모델 구동이 목적이므로 임베딩 차원 수를 크지 않게(50이하)로 설정해주세요.<br/>\n",
        "**권장사항 : `max_len` 은 텍스트 길이 평균보다 높게 설정해주세요.**<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "dHber3qBBwOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5476fce4-30c3-49d0-d763-0f27c62fcc85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 텍스트 길이 : 297.85322122612615\n"
          ]
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
        "print('평균 텍스트 길이 :', np.mean(list(map(len, X_train_tokenized))))\n",
        "del(X_train_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5AtXdyI5GgZ",
        "outputId": "a0d5a01f-eb21-4c8c-8395-ab2c5ea6bce5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125875"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 300\n",
        "def encoding(text):\n",
        "  text_encoded = tokenizer.texts_to_sequences(text)\n",
        "  text_paded = pad_sequences(text_encoded, maxlen=max_len)\n",
        "  return text_paded\n",
        "X_train_enc = encoding(X_train)\n",
        "X_test_enc = encoding(X_test)"
      ],
      "metadata": {
        "id": "GamvAuuG6k-W"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 50\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(10000, emb_dim, input_length=max_len)) # vocab_size가 너무 커서 10000으로 줄임\n",
        "model1.add(GlobalAveragePooling1D())\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "model1.fit(X_train_enc, np.array(y_train), batch_size = 32, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pob0oGAE7Vg2",
        "outputId": "6d056762-0e55-4580-8092-d45760e135a3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "898/898 [==============================] - 7s 7ms/step - loss: 0.3605 - acc: 0.9036 - val_loss: 0.1803 - val_acc: 0.9645\n",
            "Epoch 2/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.1310 - acc: 0.9724 - val_loss: 0.1089 - val_acc: 0.9776\n",
            "Epoch 3/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0856 - acc: 0.9813 - val_loss: 0.0811 - val_acc: 0.9827\n",
            "Epoch 4/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0643 - acc: 0.9855 - val_loss: 0.0665 - val_acc: 0.9859\n",
            "Epoch 5/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0509 - acc: 0.9881 - val_loss: 0.0569 - val_acc: 0.9868\n",
            "Epoch 6/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0417 - acc: 0.9905 - val_loss: 0.0495 - val_acc: 0.9883\n",
            "Epoch 7/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0344 - acc: 0.9925 - val_loss: 0.0454 - val_acc: 0.9884\n",
            "Epoch 8/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0292 - acc: 0.9936 - val_loss: 0.0407 - val_acc: 0.9907\n",
            "Epoch 9/10\n",
            "898/898 [==============================] - 6s 6ms/step - loss: 0.0252 - acc: 0.9944 - val_loss: 0.0396 - val_acc: 0.9907\n",
            "Epoch 10/10\n",
            "898/898 [==============================] - 7s 7ms/step - loss: 0.0220 - acc: 0.9952 - val_loss: 0.0367 - val_acc: 0.9905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a1d687490>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss1, acc1 = model1.evaluate(X_test_enc, y_test)\n",
        "print('loss : {:.4f}, acc : {:.4f}'.format(loss1, acc1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX8eFFKr9Cf0",
        "outputId": "65b99244-10c6-4705-b28d-f881ac452dc3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 1s 3ms/step - loss: 0.0311 - acc: 0.9919\n",
            "loss : 0.0311, acc : 0.9919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SzUwLkcAK1A"
      },
      "source": [
        "### 2.2.2 LSTM을 사용하여 텍스트 분류 수행해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UZ9ZqOAIjw"
      },
      "source": [
        "N423에서 했던 단어 임베딩 벡터의 평균을 사용하여 문장을 분류하는 작업을 수행해봅시다.<br/>\n",
        "인스턴스마다 텍스트 길이가 길어 시간이 매우 오래 걸리므로 <br/>\n",
        "**층을 최소한으로 쌓고**, epoch 수를 **3 이하**로 하는 것을 추천드립니다.<br/>\n",
        "\n",
        "> **Tip : 모델이 학습하는 동안 2.2.3의 내용을 작성하면 시간을 절약할 수 있습니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "9PLNlzEVBSyE"
      },
      "outputs": [],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs', shape=[max_len])\n",
        "    layer = Embedding(10000, emb_dim, input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256, name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1, name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs, outputs=layer)\n",
        "    return model\n",
        "\n",
        "model2 = RNN()\n",
        "model2.summary()\n",
        "model2.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train_enc, y_train, batch_size=32, epochs=3, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoF49zil-4HP",
        "outputId": "e37e78ac-9c7b-4f7a-d4a4-2e30d6d89e91"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 300, 50)           500000    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 546,337\n",
            "Trainable params: 546,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "898/898 [==============================] - 62s 66ms/step - loss: 0.1012 - accuracy: 0.9658 - val_loss: 0.0560 - val_accuracy: 0.9830\n",
            "Epoch 2/3\n",
            "898/898 [==============================] - 58s 64ms/step - loss: 0.0514 - accuracy: 0.9860 - val_loss: 0.1187 - val_accuracy: 0.9733\n",
            "Epoch 3/3\n",
            "898/898 [==============================] - 58s 65ms/step - loss: 0.0400 - accuracy: 0.9894 - val_loss: 0.1637 - val_accuracy: 0.9697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a20f5c8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss2, acc2 = model2.evaluate(X_test_enc, y_test)\n",
        "print('loss : {:.4f}, acc : {:.4f}'.format(loss2, acc2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx5Dop--_Llo",
        "outputId": "65ba464d-0668-49b8-8341-62c351b68430"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 6s 22ms/step - loss: 0.1465 - accuracy: 0.9719\n",
            "loss : 0.1465, acc : 0.9719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsNOs2wmBV1z"
      },
      "source": [
        "### 2.2.3 위에서 실행한 내용에 대해 다시 알아봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMR2t2wOEPYm"
      },
      "source": [
        "#### a) 데이터셋을 학습할 때 사용하는 `pad_sequences`  메서드에 대해 설명해주세요.<br/>어떤 기능을 하나요? 모델을 학습할 때 왜 필요한가요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7_ECWSYQ4JV"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "각 sequence(문장, input)의 길이를 똑같이 맞춰준다. input으로 들어가는 데이터의 크기를 통일해주고, 지나치게 긴 문장을 잘라 연산 시간을 줄인다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeZ6AcloEYD5"
      },
      "source": [
        "#### b) 2.2.1과 2.2.2에서 사용한 각 모델의 evaluation 성능은 어떻게 나왔나요?<br/>각 모델의 장단점은 무엇이라고 생각하나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SyqQzzHQ4EP"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*  \n",
        " 임베딩벡터의 평균을 이용한 모델 99.19%, LSTM 모델이 97.19%로 전자의 모델 성능이 조금 더 높게 나왔다.  \n",
        " Embedding만 사용하는 경우 연산 속도가 빠르지만, 문장의 맥락이 고려되지 않기 때문에 맥락이 중요한 문제에서는 좋은 성능을 발휘하지 못할 것 같다.  \n",
        " LSTM의 경우 연산 속도는 느리지만 sequence의 맥락을 학습한다는 장점이 있다. (이번 문제의 경우 문장에 사용된 단어가 중요한 feature로 작용하지 않았을까 추측됨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUwKojAGM82f"
      },
      "source": [
        "#### c) 종래의 RNN(Recurrent Neural Networks) 대신 LSTM(Long-Short Term Memory)을 사용하는 이유는 무엇인가요?<br/>(i.e. RNN에 비해 LSTM의 좋은 점을 설명해주세요.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y44XfugQ_HR"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "RNN의 기울기 소실, 폭발으로 인한 장기 의존성 문제를 LSTM은 cell-state와 기억의 정도를 조절하는 gate를 통해 해소하였다. 즉, LSTM은 RNN에 비해 긴 sequence 데이터도 잘 학습할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1kzTmDEaLU"
      },
      "source": [
        "#### d) LSTM이나 RNN을 사용하는 예시를 **3개**이상 제시하고 해당되는 경우에 왜 LSTM이나 RNN을 사용하는 것 적절한지 간단하게 설명해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck8GPjc_Q_vA"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "- 경우 : 감정 분석, 기계 번역, 주식 가격 예측\n",
        "- 적절한 이유 : 각각의 문제가 sequential한 데이터의 맥락을 파악하는 것이 중요한 문제이기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4pP7g8DE0Cz"
      },
      "source": [
        "#### e) 이외에 N424 에서 배운 자연어처리 모델과 관련된 키워드를 3개 이상 적어주세요. <br/> (해당 키워드에 대한 설명은 옵션입니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-sO4mMuRAhp"
      },
      "source": [
        "*이곳에 답안을 입력해주세요*\n",
        "- Transformer : Attention의 개념을 발전시키고 RNN 구조를 사용하지 않아 sequential한 데이터를 한번에 입력, 연산하여 학습 속도와 성능을 향상시킨 모델\n",
        "- GPT, BERT : 둘 다 Transformer 구조를 변형하여 만들었으며, 사전 학습된 언어 모델이다. 각각 NLU와 NLG에 강점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRn44qjhUo9j"
      },
      "source": [
        "# Advanced Goals: 3점을 획득하기 위해선 아래의 조건 중 하나 이상을 만족해야합니다\n",
        " \n",
        "- 2.1 에서 TF-IDF(`TfidfVectorizer`)가 아닌 방법을 사용하여 유사도 검색을 수행해보세요.<br/>\n",
        "TF-IDF와 해당 방법의 차이를 설명해주세요. \n",
        "- 2.2 에서 사용한 방법을 재사용하되 하이퍼 파라미터를 조정하거나 모델 구조를 변경하여 성능을 올려봅시다.<br/>**(주의 : GridSearch, RandomSearch 등의 방법을 사용하여도 좋으나 시간이 오래 걸리므로 범위를 잘 선택해야 합니다.)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "lz2uaXFYUo9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19dd010-3310-413a-a826-8f55154a47e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 300, 100)          1000000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                42240     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,059,137\n",
            "Trainable params: 1,059,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "898/898 [==============================] - 66s 69ms/step - loss: 0.1044 - accuracy: 0.9684 - val_loss: 0.0645 - val_accuracy: 0.9855\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 60s 66ms/step - loss: 0.0504 - accuracy: 0.9864 - val_loss: 0.0522 - val_accuracy: 0.9887\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 60s 66ms/step - loss: 0.0469 - accuracy: 0.9867 - val_loss: 0.0426 - val_accuracy: 0.9911\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 59s 66ms/step - loss: 0.0382 - accuracy: 0.9896 - val_loss: 0.0442 - val_accuracy: 0.9896\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 60s 66ms/step - loss: 0.0331 - accuracy: 0.9910 - val_loss: 0.0404 - val_accuracy: 0.9876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99a390b2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "# 이 곳에 답안을 작성하시길 바랍니다\n",
        "# 2.2 embedding dimension, epochs 조절\n",
        "def RNN():\n",
        "    inputs = Input(name='inputs', shape=[max_len])\n",
        "    layer = Embedding(10000, 100, input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256, name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1, name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs, outputs=layer)\n",
        "    return model\n",
        "\n",
        "model3 = RNN()\n",
        "model3.summary()\n",
        "model3.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "\n",
        "model3.fit(X_train_enc, y_train, batch_size=32, epochs=5, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss3, acc3 = model3.evaluate(X_test_enc, y_test)\n",
        "print('loss : {:.4f}, acc : {:.4f}'.format(loss3, acc3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taS4pWNlONzq",
        "outputId": "d93f4ac9-fd04-480a-868f-26827d4ce3f0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 [==============================] - 7s 23ms/step - loss: 0.0345 - accuracy: 0.9879\n",
            "loss : 0.0345, acc : 0.9879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0_5Uh5CsOTf6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ai08_sc42x-계윤우.ipynb",
      "provenance": []
    },
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "toc-autonumbering": false,
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}